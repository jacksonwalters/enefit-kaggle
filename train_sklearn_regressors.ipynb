{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf908791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client.csv                            gas_prices.csv\n",
      "county_id_to_name_map.json            historical_weather.csv\n",
      "electricity_prices.csv                public_timeseries_testing_util.py\n",
      "\u001b[34menefit\u001b[m\u001b[m                                train.csv\n",
      "\u001b[34mexample_test_files\u001b[m\u001b[m                    weather_station_to_county_mapping.csv\n",
      "forecast_weather.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/jacksonwalters/Documents/GitHub/enefit-kaggle/predict-energy-behavior-of-prosumers/\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c367fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from load_data import merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff9342a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data...\n",
      "loading gas_prices...\n",
      "loading electricity_prices...\n",
      "loading forecast_weather...\n",
      "merging train and gas_prices...\n",
      "merging electricity_prices...\n",
      "merging forecast_weather...\n"
     ]
    }
   ],
   "source": [
    "df = merged_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f4292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the target column and data_block_id as they are not present in test data\n",
    "X = df.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f62918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the target variable\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e285440c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify there are no NaN's\n",
    "np.any(np.isnan(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ec114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the modeling modules from sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "075b3c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532e08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a multivariable linear regression\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "regr.feature_names = list(X_train.columns.values)\n",
    "#predict on the test data\n",
    "lin_pred = regr.predict(X_test)\n",
    "print(mean_absolute_error(lin_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=5)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.feature_names = list(X_train.columns.values)\n",
    "#predict the target values using the random forest regressor\n",
    "rf_pred = rf.predict(X_test)\n",
    "#mean absolute error for random regressor\n",
    "print(mean_absolute_error(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc106798-b20c-47d9-b2c9-f86f5c586022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.357140193214846\n"
     ]
    }
   ],
   "source": [
    "hgbr = HistGradientBoostingRegressor()\n",
    "#fite the model\n",
    "hgbr.fit(X_train, y_train)\n",
    "hgbr.feature_names = list(X_train.columns.values)\n",
    "X_train.dtypes.to_csv('../models/gradient_boost_dtypes.csv')\n",
    "#predict the target values using the random forest regressor\n",
    "hgbr_pred = hgbr.predict(X_test)\n",
    "#mean absolute error for random regressor\n",
    "print(mean_absolute_error(y_test,hgbr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fdcf08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.74932818398159\n",
      "44.79244121989514\n",
      "43.59930557934766\n",
      "50.11175003921031\n",
      "51.49235091762749\n"
     ]
    }
   ],
   "source": [
    "#perform k-fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #train the model\n",
    "    rf_regr = RandomForestRegressor(n_estimators=1)\n",
    "    rf_regr.fit(X_train, y_train)\n",
    "    #predict on the test data\n",
    "    rf_pred = rf_regr.predict(X_test)\n",
    "    #evaluate the model\n",
    "    print(mean_absolute_error(rf_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4181241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "# Perform time series split cross-validation\n",
    "cross_val_scores = cross_val_score(rf, X, y, cv=tscv, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c25566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-50.24322373, -61.66098868, -36.89642564, -62.35650541,\n",
       "       -55.67914648])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b9606be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# save the linear model to disk\u001b[39;00m\n\u001b[1;32m      3\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(regr, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/linear_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mrf\u001b[49m, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/random_forest_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(hgbr, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/gradient_boost_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# save the linear model to disk\n",
    "pickle.dump(regr, open('../models/linear_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3b530be-69a9-4263-ab3d-f105862ebbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(hgbr, open('../models/gradient_boost_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021820da-969a-4930-ba80-c9e2b9d80e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf, open('../models/random_forest_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d88d68d-47fc-4fe9-8b42-90ea62cdc907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "filename = '../models/gradient_boost_model.sav'\n",
    "gb_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082b13d-aacd-4318-9f02-bc8685aef267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ML",
   "language": "python",
   "name": "venv-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
