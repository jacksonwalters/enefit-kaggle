{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3172cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client.csv                            gas_prices.csv\r\n",
      "county_id_to_name_map.json            historical_weather.csv\r\n",
      "electricity_prices.csv                public_timeseries_testing_util.py\r\n",
      "\u001b[34menefit\u001b[m\u001b[m                                train.csv\r\n",
      "\u001b[34mexample_test_files\u001b[m\u001b[m                    weather_station_to_county_mapping.csv\r\n",
      "forecast_weather.csv\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/jacksonwalters/Documents/GitHub/enefit-kaggle/predict-energy-behavior-of-prosumers/\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8fa3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8152b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 15:52:16.026753: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-15 15:52:16.026828: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "cnn_model=pickle.load(open('../models/cnn_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faaf9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from load_data import merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc6a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to convert datetime strings to integers representing a time year-month-day hour-min-sec\n",
    "from datetime import datetime\n",
    "def datestr_to_int(datetime_str,date_format):\n",
    "    if not pd.isna(datetime_str):\n",
    "        return datetime.strptime(datetime_str, date_format).timestamp()\n",
    "    else:\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd2eb990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data...\n",
      "loading gas_prices...\n",
      "loading electricity_prices...\n",
      "loading forecast_weather...\n",
      "merging train and gas_prices...\n",
      "merging electricity_prices...\n",
      "merging forecast_weather...\n"
     ]
    }
   ],
   "source": [
    "df = merged_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8528124a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1, 32)             8096      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 32)             1056      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,185\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2417b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a prediction df with all target values set to zero\n",
    "predict_df = df\n",
    "predict_df['target'] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00babb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test-train-validation split on the data\n",
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "num_features = df.shape[1]\n",
    "\n",
    "#normalize the training data\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "if train_std['target'] == 0.:\n",
    "    print(\"AHHHHHH!!!!!\")\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n",
    "\n",
    "#Handle the indexes and offsets as shown in the diagrams above.\n",
    "#Split windows of features into (features, labels) pairs.\n",
    "#Plot the content of the resulting windows.\n",
    "#Efficiently generate batches of these windows from the training, evaluation, and test data, using tf.data.Datasets.\n",
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df, test_df=test_df,predict_df=predict_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "    self.predict_df = predict_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack([labels[:, :, self.column_indices[name]] for name in self.label_columns],axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window\n",
    "\n",
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=32,)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset\n",
    "\n",
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def predict(self):\n",
    "  return self.make_dataset(self.predict_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.predict = predict\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-step dense network\n",
    "CONV_WIDTH = 9\n",
    "conv_window = WindowGenerator(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    label_columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dd82fb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 10\n",
       "Input indices: [0 1 2 3 4 5 6 7 8]\n",
       "Label indices: [9]\n",
       "Label column name(s): ['target']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conv_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d8642f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (32, 9, 28)\n",
      "Output shape: (32, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Input shape:', conv_window.example[0].shape)\n",
    "print('Output shape:', cnn_model(conv_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cf127234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "array([[[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]]], dtype=float32)>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window.example[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c2e4afff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]],\n",
       "\n",
       "       [[0.2711371]]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.predict(conv_window.example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "96e26d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "array([[[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]],\n",
       "\n",
       "       [[nan]]], dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note that the train, test, validation data all have a second \"label\"representing the target value\n",
    "cnn_model.predict(conv_window.example[0]) - conv_window.example[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6bd52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
